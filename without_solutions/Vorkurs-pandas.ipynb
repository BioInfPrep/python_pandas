{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Introduction to the `pandas` data analysis library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a Jupyter notebook for the final Python session of the Vorkurs, and introduce the `pandas` data analysis library.\n",
    "\n",
    "Jupyter notebooks allow you to write Python code interactively in your browser, and display the code's intermediate outputs (text, tables or plots) in-place. Jupyter notebooks are structured into three kinds of cells:\n",
    "1. Markdown text (like the one you're currently reading)\n",
    "2. Code\n",
    "3. Output\n",
    "\n",
    "Code cells can be run one-by-one, as opposed to executing an entire Python program in one go. Code cells that you execute (with the `Run` button or `Ctrl+Enter`) have lasting effects: all the variables set by previously executed code cells will be available for later cells.\n",
    "\n",
    "You can edit and re-run cells freely, but keep in mind that your program's internal state depends on what you had previously run, which isn't necessarily consistent with what you see on your screen. E.g. if you execute a cell containing `a = 1`, then change it to `b = 1` and re-run it: variable `a` won't disappear, it will still be available for later cells until you restart your session.\n",
    "\n",
    "Upon the execution of a cell, the last line of the cell's code will be additionally printed and placed below the cell by default, which is a useful feature to inspect intermediate results. Try it by running this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"I can check stuff without explicit print statements like this\")\n",
    "a = 5\n",
    "b = 3\n",
    "\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You saw that running the code cell created an output cell below it. This is how we will use Jupyter notebooks and look at our intermediate outputs.\n",
    "\n",
    "You can take a look at [Jupyter keyboard shortcuts](https://www.cheatography.com/weidadeyue/cheat-sheets/jupyter-notebook/) to help you format and interact with your notebooks efficiently. The important parts:\n",
    "\n",
    "You can insert a new cell anywhere by clicking on the left margin of a cell, and pressing `b` (for below) or `a` (for above). If the left border of a cell is blue, you are in navigation mode. If it's green, you are in editing mode. You can switch between them with `Escape` and `Enter`. You can run a code cell with `Ctrl+Enter`. In nagivation mode, you can move between cells using the `Up` or `Down` keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try navigating, inserting, editing and executing code cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "The purpose of this notebook is to give an introduction to the `pandas` data analysis library. `pandas` provides data structures and various kinds of operations for handling tabular data.\n",
    "\n",
    "The basic object types are `Series` (1-dimensional data, like a list) and `DataFrame` (2-dimensional data, like a table). These objects have a lot of fancy features that plain old Python lists, or even `numpy` arrays don't. They offer label-based indexing, slicing, grouping, aggregation, merging, reshaping, pivoting, and a host of other manipulation methods, as well as some visualization capabilities using `matplotlib` or `seaborn`. DataFrames also support pretty HTML table outputs inside Jupyter notebooks by default.\n",
    "\n",
    "Pandas has extensive online documentation, and you may find their [10 Minutes Introduction](http://pandas.pydata.org/pandas-docs/stable/10min.html) and their [tutorials](http://pandas.pydata.org/pandas-docs/stable/tutorials.html) especially useful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pandas\n",
    "\n",
    "Conventionally `pandas` is imported under the name `pd`. There are a few other conventions such as `numpy as np` or the visualization library `seaborn as sns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pandas `Series` object named `s` with the following data:\n",
    "\n",
    "|     |\n",
    "|-----|\n",
    "| 3.0 |\n",
    "| 1.5 |\n",
    "| 4.3 |\n",
    "| 8.2 |\n",
    "| 0.9 |\n",
    "\n",
    "Now\n",
    "* Access its first value\n",
    "* Access its last value\n",
    "* Calculate its mean and standard deviation\n",
    "* Sort it in ascending and descending order\n",
    "\n",
    "Use a separate code block for each operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the sorted `Series` in variable `s2`. Notice how the index labels moved together with the values. Positional (`.iloc[]`) and label-based (`.loc[]`) access behave very differently now, try them out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame objects, accessing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `DataFrame` named `df_species` with the following data:\n",
    "\n",
    "| |species |weight  |legs |\n",
    "|--------|--|---|----|\n",
    "|<b>0</b>|human |62  |2 |\n",
    "|<b>1</b>|cat   |4  |4 |\n",
    "|<b>2</b>|mouse |0.02  |4 |\n",
    "|<b>3</b>|dog   |20 |4 |\n",
    "|<b>4</b>|mole  |0.09  |4 |\n",
    "|<b>5</b>|train |200000 |0 |\n",
    "|<b>6</b>|bee   |0.0001 |6  |\n",
    "|<b>7</b>|elephant |3000 |4 |\n",
    "\n",
    "You can pass the data to the `DataFrame(...)` constructor column-by-column as a dictionary (keys: column labels, values: list of column values), or row-by-row using nested lists. In the latter case, you have to additionally specify the column labels using the `columns=` keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in separate cells\n",
    "* access the 3rd row of `df_species`. What type is the resulting object?\n",
    "* access the row with index `3`\n",
    "* access the column `weight`\n",
    "* access a single cell (e.g. dog's number of legs)\n",
    "* print the index and column labels\n",
    "* extract rows 2-5 into a new DataFrame (no need to save it)\n",
    "* obtain a summary table of the DataFrame with the means, standard deviations, min/max/percentiles of the numerical columns\n",
    "* add a new column `weight_in_lb` to the DataFrame containing the weights in pounds instead of kilograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `df_characters.csv` file into a DataFrame named `df`, and display it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import the file `df_countries.tsv` into a pandas DataFrame as `df_countries`. Do you need to change any parameters of the importing function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame filtering\n",
    "\n",
    "The DataFrame access method `.loc[]` can take:\n",
    "* individual index labels (as seen previously)\n",
    "* lists of index labels\n",
    "* slices in the `beginning:end` format (also seen previously)\n",
    "* boolean valued `Series` objects, where only labels with `True` value are kept\n",
    "\n",
    "For the upcoming task, the last method will be especially useful. Using the cartoon character DataFrame `df`, filter them for the following criteria (separately) and display the results:\n",
    "\n",
    "* German characters\n",
    "* Characters born after 1970\n",
    "* Human characters weighing <60 kg\n",
    "\n",
    "Tips: You can perform boolean comparisons for an entire `Series` with the usual `>`, `<`, `==`, `!=` etc operators. You can do elementwise logical operations between two conforming `Series` objects using the `&` or `|` operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce a new column named `age` based on the characters' birthdates. Answer the following questions:\n",
    "\n",
    "* What is the average age of the characters?\n",
    "* Who is the youngest German character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame aggregation\n",
    "\n",
    "Using the same DataFrame `df`\n",
    "* Count the number of characters from each country\n",
    "* Calculate the average weight and age of characters by species\n",
    "* List the heaviest characters per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging DataFrames\n",
    "\n",
    "By combining information from the DataFrames above we can try to answer more complex queries. For example, the number of legs for a given character isn't stored in the `df` DataFrame, but it is available in the `df_species` DataFrame if we look up the corresponding entry of the character's species. If we could combine the two into a single DataFrame, we could create queries using character-specific **and** species-specific data at the same time.\n",
    "\n",
    "Combining tables based on shared keys is called merging. Pandas allows you to do it with either the function `pd.merge` or as a DataFrame method `df.merge`. All you have to do is specify the two DataFrames that you want to merge (the first one is already implied if you use it as a method) and the column label(s) that you want to merge them on.\n",
    "\n",
    "Merge `df` and `df_species` into a new DataFrame named `dfm` and answer the following questions:\n",
    "\n",
    "* What is the average age of four-legged characters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the average weight of four-legged characters?\n",
    "\n",
    "Although the question sounds nearly identical to the previous one, you may notice that something happened to your original character `weight` column. Since the column name was contained in both DataFrames, they had to be renamed during the merge to avoid a collision. You can control how to rename them with the `suffixes` keyword argument. We suggest that you set them to `_indiv` and `_species` so you can distinguish `weight_indiv` (the character's weight) from `weight_species` (their species' typical weight)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Has any character gone missing during the merge?\n",
    "\n",
    "Why is that? How could you ensure that they aren't thrown out? Hint: the `merge` function/method has a keyword argument `how`. You can either go back to the cell where you created `dfm` and update it, or you can overwrite `dfm` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the characters' relative weight as a ratio of the typical weight of their species, and add it as a new column `rel_weight`.\n",
    "\n",
    "Of course you won't be able to calculate that for characters whose species data wasn't available. But that's okay, `pandas` can handle operations with missing values wisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's answer some queries based on the characters' countries of origin:\n",
    "* How many characters are there from each continent?\n",
    "* Which character comes from the smallest country?\n",
    "\n",
    "For this you have to merge `df` and `df_countries` (let's call the result `dfm2`). There's one little issue: the shared key is labelled differently in the two DataFrames. Thankfully the `merge` function/method allows you to specify them independently for the left and right DataFrame if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, a question that requires information from all three DataFrames:\n",
    "\n",
    "* Who is the most overweight European character?\n",
    "\n",
    "You can't directly merge three DataFrames with a single operation, but you can merge `dfm` with `df_countries` easily enough. Let's call this resulting \"mega-merge\" as `df_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group filtering\n",
    "\n",
    "You can either continue working with `df` or `df_all`, it won't matter for the next task:\n",
    "\n",
    "* List characters that are the sole entries of their country\n",
    "\n",
    "To answer this question, you can use the `filter` method of `GroupBy` objects. It is similar to the aggregation methods like `mean`, `size` or `first` that we had used before, but instead of returning a single row per group, it either returns all rows of the group or none of them.\n",
    "\n",
    "It expects a simple function as an argument. The function's input will be a DataFrame containing all rows of a group, and it should return a boolean `True/False` value. If the returned value is `True`, the group will be kept, otherwise it will be discarded.\n",
    "\n",
    "Of course you can experiment with alternative solutions too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping using derived keys\n",
    "\n",
    "* Count characters by decade of birth -- without inserting a new column!\n",
    "\n",
    "So far, we have always used a column label as `groupby`'s argument. If we wanted to group rows based on data that isn't explicitly contained in the DataFrame, we would've had to insert a new column with the data, and group by that new column.\n",
    "\n",
    "Thankfully, `groupby` also accepts a `Series` object as an argument, and group the DataFrame according to the values of that Series, without having to insert that Series into the DataFrame.\n",
    "\n",
    "Hint: you can round a number down to the nearest ten with the full division operator by `x // 10 * 10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data export\n",
    "\n",
    "Export `df_all` into `characters_merged.tsv` in tab-separated format with question marks in place of N/A values, and omit the index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
